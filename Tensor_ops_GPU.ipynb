{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "### Tensor operations"
      ],
      "metadata": {
        "id": "OFuMMKhgxHFF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# pytorch is preinstalled on google collab\n",
        "# else: pip install torch\n",
        "\n",
        "import torch\n",
        "print(torch.__version__)\n",
        "\n",
        "# checking if GPU available\n",
        "# get_device_name  : shows which GPU is available\n",
        "# as of now shows CPU : If needed GPU : change runtime type : GPU\n",
        "\n",
        "if torch.cuda.is_available():\n",
        "    print(\"GPU is available!\")\n",
        "    print(f\"Using GPU: {torch.cuda.get_device_name(0)}\")\n",
        "else:\n",
        "    print(\"GPU not available. Using CPU.\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jvpx_CvAw7ig",
        "outputId": "e8ee79e2-84cc-4434-f00a-e9491076117c"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "2.5.1+cu121\n",
            "GPU is available!\n",
            "Using GPU: Tesla T4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "torch.cuda.is_available()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qa3UMjSNw7lD",
        "outputId": "ce1d429c-683e-4a0f-a7e4-9441bbb4ba47"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# we will now store our GPU device and assign it to a variable\n",
        "\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "device"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ko5M5bWmw7nQ",
        "outputId": "3141f3c2-d36b-49a3-91b1-305a6ef243f7"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "device(type='cuda')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# creating a new tensor on GPU\n",
        "\n",
        "torch.rand(size=(2,3), device=device)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2zRQ3W3Sw7pc",
        "outputId": "1cb66e07-d1ee-4d99-a7e8-a5f5e323c0ea"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.6934, 0.0343, 0.4571],\n",
              "        [0.6496, 0.5724, 0.6945]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VJ2wswnUw7sK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# moving an existing tensor on CPU onto GPU\n",
        "\n",
        "# create a tensor on CPU\n",
        "\n",
        "a = torch.rand(size=(2,3))\n",
        "\n",
        "a\n",
        "# this tensor lies on CPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qCuajAxow7uP",
        "outputId": "00059dfe-65cc-41f4-8242-e385a909ea81"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0873, 0.2355, 0.2195],\n",
              "        [0.9818, 0.4430, 0.3167]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = a.to(device)\n",
        "b\n",
        "# this tensor lies on GPU"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O_dHYsgbw7wU",
        "outputId": "88e4ffe9-2cc6-4450-93fa-875fa8c8ef99"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0.0873, 0.2355, 0.2195],\n",
              "        [0.9818, 0.4430, 0.3167]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# now whatever operations you do , they will be done on GPU\n",
        "b + 5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tfRoxtnjw7yK",
        "outputId": "c497be17-51b9-453e-8b27-5356dcf424c6"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5.0873, 5.2355, 5.2195],\n",
              "        [5.9818, 5.4430, 5.3167]], device='cuda:0')"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# create a 10000 x 10000 matrix\n",
        "\n",
        "import time\n",
        "import torch\n",
        "\n",
        "# define the size\n",
        "size = 10000\n",
        "\n",
        "# create two matrices on cpu\n",
        "matrix_cpu1 = torch.rand(size, size)\n",
        "matrix_cpu2 = torch.rand(size, size)\n",
        "\n",
        "# measure the time on CPU\n",
        "start_time = time.time()\n",
        "result_cpu = torch.matmul(matrix_cpu1, matrix_cpu2)\n",
        "cpu_time = time.time() - start_time\n",
        "\n",
        "\n",
        "print(f\"Time on CPU : {cpu_time:.4f} seconds \")\n",
        "\n",
        "# move matrices on GPU\n",
        "matrix_gpu1 = matrix_cpu1.to('cuda')\n",
        "matrix_gpu2 = matrix_cpu2.to('cuda')\n",
        "\n",
        "# measure the time on GPU\n",
        "\n",
        "start_time = time.time()\n",
        "result_gpu = torch.matmul(matrix_gpu1, matrix_gpu2)\n",
        "torch.cuda.synchronize()\n",
        "gpu_time = time.time() - start_time\n",
        "\n",
        "print(f\"Time on GPU : {gpu_time:.4f} seconds \")\n",
        "\n",
        "#compare results and the gain\n",
        "\n",
        "print(\"Gain\",cpu_time/gpu_time)\n",
        "# this means the job that takes 30 hours on a CPU can be finished on a GPU in an hour\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OmhhJDyDw70E",
        "outputId": "8619e815-a255-460e-d292-e9e662ef6c8f"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Time on CPU : 17.4845 seconds \n",
            "Time on GPU : 0.5739 seconds \n",
            "Gain 30.46778297887014\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WNgQSHhBw72S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "KmooYAkAw74Y"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "WQh1eDk1w-MW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "d4GJgsFaw-Ol"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Vdcp7D4vw-Rs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SxI--Zm5w-Tx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "eHu_qYJOw-V9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U28u-djlw-YN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "emV9hNcgw-ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "YkpZ0t0mw-ce"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "xnJ09-RQw-e5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "VAZm4m9Vw-hW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "97ZCfjfCw-jx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XkpNVnBzw-l_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FCp_5Qv-w-oa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XQizzyTMw-qu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "2nZozIqxw-sw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "qFy2dKqXw-u0"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}